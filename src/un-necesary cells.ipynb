{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92576fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional cell \n",
    "# adding path on both ways either we work like running pythn liek program in pythonscript.py or in interactive mode (UI) \n",
    "import os\n",
    "\n",
    "try:\n",
    "    # when running as a .py file\n",
    "    ROOT = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    # when running in a notebook\n",
    "    ROOT = os.getcwd()\n",
    "\n",
    "RAW_DIR = os.path.join(ROOT, \"data\", \"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL DONT RUN IT! \n",
    "# Tell Python where to find src/ At the top of your notebook:\n",
    "import os, sys\n",
    "\n",
    "# adjust the path so Python can import from src/\n",
    "sys.path.insert(0, os.path.abspath(\"src\"))\n",
    "\n",
    "# now you can import your ETL functions\n",
    "from transform_load import load_raw_items, normalize, create_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DONT RUN IT!\n",
    "# Override RAW-DIR if needed\n",
    "# after importing, re-point RAW_DIR for notebook context\n",
    "from transform_load import RAW_DIR as _orig_raw_dir\n",
    "import os\n",
    "RAW_DIR = os.path.abspath(\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL DONT RUN IT!\n",
    "# Run your pipeline interactively\n",
    "raw = load_raw_items(RAW_DIR)\n",
    "dates, sources, authors, pubs, pub_auth = normalize(raw)\n",
    "create_and_load(dates, sources, authors, pubs, pub_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation script \n",
    "# DODATNO UREDJIVANJE VIDETI KAKO DA SE TOKENIZUJU KREDENCIJALI DA NE BUDU \"OGOLJENI\" U SKRIPTI \n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def validate_mysql_connection(db_user, db_password, db_host, db_name):\n",
    "    \n",
    "    connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\"\n",
    "    engine = create_engine(connection_string) #None  # Initialize engine outside try block\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Execute a simple query to verify connection\n",
    "            version = conn.execute(text(\"SELECT DATABASE();\")).scalar()\n",
    "            print(f\"Successfully connected to MySQL. Database version: {version}\")\n",
    "            return True\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error connecting to MySQL: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if engine:\n",
    "            engine.dispose() # Dispose of the engine to close connections in the pool\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "# Replace with your actual database credentials\n",
    "    USER = \"Milosh_85\"\n",
    "    PASSWORD = \"Nikoljdan2021\"\n",
    "    HOST = \"127.0.0.1\"\n",
    "    DATABASE = \"scilit_db\"\n",
    "\n",
    "validate_mysql_connection(USER, PASSWORD, HOST, DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce872ced",
   "metadata": {},
   "source": [
    "### adding solution from Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Create your engine (dialect “mysql+pymysql” is correct)\n",
    "engine = create_engine(\"mysql+pymysql://Milosh_85:Nikoljdan2021@127.0.0.1:3306/scilit_db\")\n",
    "\n",
    "TABLE_ORDER = [\n",
    "    \"publication_authors\",\n",
    "    \"publications\",\n",
    "    \"authors\",\n",
    "    \"sources\",\n",
    "    \"dates\"\n",
    "]\n",
    "\n",
    "DDL = [\n",
    "    # Drop in reverse‐dependency order:\n",
    "    \"DROP TABLE IF EXISTS publication_authors;\",\n",
    "    \"DROP TABLE IF EXISTS publications;\",\n",
    "    \"DROP TABLE IF EXISTS authors;\",\n",
    "    \"DROP TABLE IF EXISTS sources;\",\n",
    "    \"DROP TABLE IF EXISTS dates;\",\n",
    "\n",
    "    # Recreate:\n",
    "    \"\"\"\n",
    "    CREATE TABLE dates (\n",
    "      date_id   INT PRIMARY KEY,\n",
    "      year      INT,\n",
    "      month     INT,\n",
    "      day       INT\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE sources (\n",
    "      source_id   INT PRIMARY KEY,\n",
    "      source_name VARCHAR(255)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE authors (\n",
    "      author_id    INT PRIMARY KEY,\n",
    "      given_name   VARCHAR(100),\n",
    "      family_name  VARCHAR(100),\n",
    "      affiliation  VARCHAR(255)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE publications (\n",
    "      publication_id   INT PRIMARY KEY,\n",
    "      doi              VARCHAR(255),\n",
    "      title            TEXT,\n",
    "      publisher        VARCHAR(255),\n",
    "      type             VARCHAR(50),\n",
    "      source_id        INT,\n",
    "      issued_date_id   INT,\n",
    "      FOREIGN KEY (source_id)      REFERENCES sources(source_id),\n",
    "      FOREIGN KEY (issued_date_id) REFERENCES dates(date_id)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE publication_authors (\n",
    "      publication_id   INT,\n",
    "      author_id        INT,\n",
    "      sequence         INT,\n",
    "      PRIMARY KEY (publication_id, author_id),\n",
    "      FOREIGN KEY (publication_id) REFERENCES publications(publication_id),\n",
    "      FOREIGN KEY (author_id)      REFERENCES authors(author_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "def create_and_load(dates, sources, authors, pubs, pub_auth):\n",
    "    # 1) Drop & recreate schema\n",
    "    with engine.begin() as conn:\n",
    "        for stmt in DDL:\n",
    "            conn.execute(text(stmt))\n",
    "\n",
    "        # 2) Bulk load INTO that same connection\n",
    "        pd.DataFrame(dates) .to_sql(\"dates\",                conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(sources).to_sql(\"sources\",             conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(authors).to_sql(\"authors\",             conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(pubs)   .to_sql(\"publications\",        conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(pub_auth).to_sql(\"publication_authors\",conn, if_exists=\"append\", index=False)\n",
    "\n",
    "    print(\"✅ All tables created and loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f352f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option b with adding a raw DBAPI connection to pandas \n",
    "\n",
    "# hand pandas an object that actually has .cursor(). The simplest is engine.raw_connection(). \n",
    "# For example, move your inserts outside the with engine.begin() block :\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://Milosh_85:Nikoljdan2021@127.0.0.1:3306/scilit_db\")\n",
    "    #engine = create_engine(DB_URI, echo=False)\n",
    "\n",
    "def create_and_load(dates, sources, authors, pubs, pub_auth):\n",
    "    \"\"\"Drop & recreate tables, then bulk-insert via pandas.to_sql().\"\"\"\n",
    "    \n",
    "    # 1) Dropping part (DDl) - Drop in reverse-dependency order Child tables \n",
    "    # with FKs go first so you don’t violate referential integrity when dropping\n",
    "    drop_order = [\n",
    "         \"publication_authors\",\n",
    "         \"publications\",\n",
    "         \"authors\",\n",
    "         \"sources\",\n",
    "         \"dates\"\n",
    "        ]\n",
    "    # 2) Create tables (DDL) (parent → child)\n",
    "    ddl_statements = [\n",
    "        \"\"\"\n",
    "        CREATE TABLE dates (\n",
    "          date_id INT NOT NULL,\n",
    "          year INT,\n",
    "          month INT,\n",
    "          day INT,\n",
    "          PRIMARY KEY (date_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE sources (\n",
    "          source_id INT NOT NULL,\n",
    "          source_name VARCHAR(255),\n",
    "          PRIMARY KEY (source_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE authors (\n",
    "          author_id INT NOT NULL,\n",
    "          given_name VARCHAR(100),\n",
    "          family_name VARCHAR(100),\n",
    "          affiliation VARCHAR(255),\n",
    "          PRIMARY KEY (author_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE publications (\n",
    "          publication_id INT NOT NULL,\n",
    "          doi VARCHAR(255),\n",
    "          title VARCHAR(255),\n",
    "          publisher VARCHAR(255),\n",
    "          type VARCHAR(50),\n",
    "          source_id INT,\n",
    "          issued_date_id INT,\n",
    "          PRIMARY KEY (publication_id),\n",
    "          FOREIGN KEY (source_id) REFERENCES sources(source_id),\n",
    "          FOREIGN KEY (issued_date_id) REFERENCES dates(date_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE publication_authors (\n",
    "          publication_id INT,\n",
    "          author_id INT,\n",
    "          sequence INT,\n",
    "          PRIMARY KEY (publication_id, author_id),\n",
    "          FOREIGN KEY (publication_id) REFERENCES publications(publication_id),\n",
    "          FOREIGN KEY (author_id) REFERENCES authors(author_id)\n",
    "        )\"\"\"\n",
    "        ]\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for tbl in drop_order:\n",
    "            conn.execute(text(f\"DROP TABLE IF EXISTS {tbl}\"))\n",
    "        for stmt in ddl_statements:\n",
    "            conn.execute(text(stmt))\n",
    "            \n",
    "#3  Bulk‐load via pandas, using a raw DBAPI connection (moving to-sql() part out of the with engine.begin() block)\n",
    "        raw_conn = engine.raw_connection()\n",
    "        try:\n",
    "            pd.DataFrame(dates).to_sql(\n",
    "                name=\"dates\",\n",
    "                con=raw_conn,\n",
    "                if_exists=\"append\",\n",
    "                index=False\n",
    "            )\n",
    "            pd.DataFrame(sources).to_sql(name = \"sources\", con=conn, if_exists=\"append\", index=False)\n",
    "            pd.DataFrame(authors).to_sql(name = \"authors\", con=conn, if_exists=\"append\", index=False)\n",
    "            pd.DataFrame(pubs).to_sql(name = \"publications\", con=conn, if_exists=\"append\", index=False)\n",
    "            pd.DataFrame(pub_auth).to_sql(name = \"publication_authors\", con=conn, if_exists=\"append\", index=False)\n",
    "            raw_conn.commit()\n",
    "        finally:\n",
    "            raw_conn.close()\n",
    "\n",
    "print(\"All tables created and loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option c:with using SQLAlchemy.Connection  \n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://Milosh_85:Nikoljdan2021@127.0.0.1:3306/scilit_db\")\n",
    "    #engine = create_engine(DB_URI, echo=False)\n",
    "\n",
    "def create_and_load(dates, sources, authors, pubs, pub_auth):\n",
    "    \"\"\"Drop & recreate tables, then bulk-insert via pandas.to_sql().\"\"\"\n",
    "    \n",
    "    # 1) Dropping part (DDl) - Drop in reverse-dependency order Child tables \n",
    "    # with FKs go first so you don’t violate referential integrity when dropping\n",
    "    drop_order = [\n",
    "        \"publication_authors\",\n",
    "        \"publications\",\n",
    "        \"authors\",\n",
    "        \"sources\",\n",
    "        \"dates\"\n",
    "    ]\n",
    "    # 2) Create tables (DDL) (parent → child)\n",
    "    ddl_statements = [\n",
    "        \"\"\"\n",
    "        CREATE TABLE dates (\n",
    "          date_id INT NOT NULL,\n",
    "          year INT,\n",
    "          month INT,\n",
    "          day INT,\n",
    "          PRIMARY KEY (date_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE sources (\n",
    "          source_id INT NOT NULL,\n",
    "          source_name VARCHAR(255),\n",
    "          PRIMARY KEY (source_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE authors (\n",
    "          author_id INT NOT NULL,\n",
    "          given_name VARCHAR(100),\n",
    "          family_name VARCHAR(100),\n",
    "          affiliation VARCHAR(255),\n",
    "          PRIMARY KEY (author_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE publications (\n",
    "          publication_id INT NOT NULL,\n",
    "          doi VARCHAR(255),\n",
    "          title VARCHAR(255),\n",
    "          publisher VARCHAR(255),\n",
    "          type VARCHAR(50),\n",
    "          source_id INT,\n",
    "          issued_date_id INT,\n",
    "          PRIMARY KEY (publication_id),\n",
    "          FOREIGN KEY (source_id) REFERENCES sources(source_id),\n",
    "          FOREIGN KEY (issued_date_id) REFERENCES dates(date_id)\n",
    "        )\"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE publication_authors (\n",
    "          publication_id INT,\n",
    "          author_id INT,\n",
    "          sequence INT,\n",
    "          PRIMARY KEY (publication_id, author_id),\n",
    "          FOREIGN KEY (publication_id) REFERENCES publications(publication_id),\n",
    "          FOREIGN KEY (author_id) REFERENCES authors(author_id)\n",
    "        )\"\"\"\n",
    "        ]\n",
    "\n",
    "    with engine.begin() as sa_conn:\n",
    "        for tbl in drop_order:\n",
    "            sa_conn.execute(text(f\"DROP TABLE IF EXISTS {tbl}\"))\n",
    "        for stmt in ddl_statements:\n",
    "            sa_conn.execute(text(stmt))\n",
    "            \n",
    "    # 3) Bulk insert (we call con=engine instead of conn, as pandas nwo recognizes the engine and internally calls DBAPI to to the insert)\n",
    "        pd.DataFrame(dates).to_sql(name = \"dates\", con=sa_conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(sources).to_sql(name = \"sources\", con=sa_conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(authors).to_sql(name = \"authors\", con=sa_conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(pubs).to_sql(name = \"publications\", con=sa_conn, if_exists=\"append\", index=False)\n",
    "        pd.DataFrame(pub_auth).to_sql(name = \"publication_authors\", con=sa_conn, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"All tables created and loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ab2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame(dates)\n",
    "dates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d4850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d6017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
